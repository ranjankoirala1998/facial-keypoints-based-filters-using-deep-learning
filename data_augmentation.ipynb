{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd09687db10b31693f3c59eabc6c1cee59a08ac30446d3a4b6004efe89aebdb61cf",
   "display_name": "Python 3.9.2 64-bit ('env')"
  },
  "metadata": {
   "interpreter": {
    "hash": "9687db10b31693f3c59eabc6c1cee59a08ac30446d3a4b6004efe89aebdb61cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1>NOTE :</h1> \n",
    "<h2># code -> commented code </h2>\n",
    "<h2>## comment -> comment on executed code </h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## importing necessary librabies and modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('datasets\\clean.csv')\n",
    "\n",
    "## read from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.columns.to_list()\n",
    "\n",
    "## the training set has altogether 31 columns; 30 columns for the x- and y- coordinate of 15 facial key-points and 1 column for the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.info()\n",
    "\n",
    "## we can see the data type for each columns ; 30 columns has float type and the last 1 column has image object"
   ]
  },
  {
   "source": [
    "## Lets see how our image looks like"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_image = train_set['Image'][0]\n",
    "# print(sample_image)\n",
    "# print(type(sample_image))\n",
    "\n",
    "## our image is a string object which contains the gray values (ranging from 0-255) for each pixels separated by space; \n",
    "## we need to convert the string type into a numpy array of these gray values; \n",
    "## later we reshape this array in order to represent a 96x96 grayscale image\n"
   ]
  },
  {
   "source": [
    "## converting string object to three dimensional numpy array of shape(96, 96, 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['Image'] = train_set['Image'].apply(lambda x : np.reshape(np.array(x.split(' '), dtype=int), (96, 96, 1)))\n",
    "\n",
    "## applying lambda function to convert the str type into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = train_set['Image'][0]\n",
    "# print(type(image))\n",
    "\n",
    "## now our image is no more a string object but rather it is a three dimensional numpy array of size(96, 96, 1); "
   ]
  },
  {
   "source": [
    "## defining some functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(image, keypoint, axis, title):\n",
    "    axis.imshow(image, cmap='gray')\n",
    "    axis.scatter(keypoint[0::2], keypoint[1::2], marker='o', s=10)\n",
    "    plt.title(title)\n",
    "\n",
    "## this function is used to plot both image and the keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(train_set):\n",
    "    images = []\n",
    "    for idx, image in train_set.iterrows():\n",
    "        images.append(image['Image'])\n",
    "    images = np.array(images)/255. # normalized the gray-value in the range 0-1\n",
    "    return images\n",
    "\n",
    "## this function is used to generate a list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints(train_set):\n",
    "    temp = train_set.drop('Image', axis = 1) # dropping everything from the 'Image' column; doing so, only the keypoints remains\n",
    "    keypoints = []\n",
    "    for idx, keypoint in temp.iterrows():\n",
    "        keypoints.append(keypoint)\n",
    "    keypoints = np.array(keypoints, dtype = 'float')\n",
    "    return keypoints\n",
    "\n",
    "## this function is used to generate a list of keypoints"
   ]
  },
  {
   "source": [
    "## lets prepare our training keypoints and images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keypoints = load_keypoints(train_set)\n",
    "train_images = load_images(train_set)"
   ]
  },
  {
   "source": [
    "## lets plot a sample image as well as the 15 facial keypoints"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_index = 48\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "plot_sample(train_images[sample_image_index], train_keypoints[sample_image_index], axis, \"Sample Image with Facial Keypoints\")"
   ]
  },
  {
   "source": [
    "## For training our neural network, the data-points might not be enough. So to increase the number of data points, we will perform data augmentation. Data augmentation is a technique to increase the diversity of our training set by applying random (but realistic) transformations such as image rotation, flipping, shifting, blurring, etc.\n",
    "## Due to resoures limitation, we will only perform two types of augmentation : reflection and ..., after which we will be having around 8k instances of data; which will be enough for training the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Augmentation 1 : Image Flipping or Reflection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}